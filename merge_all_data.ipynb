{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sebastiano Busato\n",
    "Date: 01/03/2023\n",
    "What this code does: read each file, remove missing rows, do some other fun stuff, then merge "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dataset: read the training trait data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/1_Training_Trait_Data_2014_2021_MODSB.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out desired columns\n",
    "df1_filt = df1.loc[:,['Env', 'Year', 'Field_Location', 'Hybrid_orig_name', 'Plot_Area_ha', 'plantdate_parsed','harvestdate_parsed','Yield_Mg_ha']]\n",
    "#remove rows with missing yield \n",
    "df1_filt = df1_filt[~df1_filt['Yield_Mg_ha'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# are there remaining NAs?\n",
    "df1_filt[df1_filt.isnull().any(axis=1)] #yes\n",
    "df1_filt.isnull().sum() # only in date harvested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1_dates = df1_filt.loc[:,['plantdate_parsed','harvestdate_parsed']]\n",
    "df1_dates['harvestdate_parsed'] = pd.to_datetime(df1_dates['harvestdate_parsed'], errors='coerce',yearfirst=True)\n",
    "df1_dates['plantdate_parsed'] = pd.to_datetime(df1_dates['plantdate_parsed'], errors='coerce',yearfirst=True)\n",
    "df1_dates['days_growth'] = df1_dates['harvestdate_parsed']-df1_dates['plantdate_parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dates['days_growth'].mean() #mean growth is 159 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out values of plantdate where harvestdate is missing\n",
    "a = df1_filt.loc[df1_filt['harvestdate_parsed'].isnull(),['plantdate_parsed']]\n",
    "#convert to datetime and add 159 days\n",
    "b = pd.to_datetime(a['plantdate_parsed'], errors='coerce',yearfirst=True)+pd.to_timedelta('159 days')\n",
    "#replace missing values with calculations\n",
    "df1_filt.loc[df1_filt['harvestdate_parsed'].isnull(),['harvestdate_parsed']] = b\n",
    "\n",
    "df1_filt.isnull().sum()\n",
    "#no more missing! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Import and modify metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/2_Training_Meta_Data_2014_2021.csv\", encoding='latin-1')\n",
    "df2_filt = df2.loc[:,['Env', 'Year', 'Experiment_Code', 'Treatment', 'City', 'Farm', 'Field',\n",
    "       'Soil_Taxonomic_ID and horizon description, if known',\n",
    "       'Weather_Station_Serial_Number (Last four digits, e.g. m2700s#####)',\n",
    "       'Weather_Station_Latitude (in decimal numbers NOT DMS)',\n",
    "       'Weather_Station_Longitude (in decimal numbers NOT DMS)',\n",
    "       'Date_weather_station_placed', 'Date_weather_station_removed',\n",
    "       'Previous_Crop', 'Pre-plant_tillage_method(s)',\n",
    "       'In-season_tillage_method(s)',\n",
    "       'Type_of_planter (fluted cone; belt cone; air planter)',\n",
    "       'System_Determining_Moisture', 'Pounds_Needed_Soil_Moisture',\n",
    "       'Latitude_of_Field_Corner_#1 (lower left)',\n",
    "       'Longitude_of_Field_Corner_#1 (lower left)',\n",
    "       'Latitude_of_Field_Corner_#2 (lower right)',\n",
    "       'Longitude_of_Field_Corner_#2 (lower right)',\n",
    "       'Latitude_of_Field_Corner_#3 (upper right)',\n",
    "       'Longitude_of_Field_Corner_#3 (upper right)',\n",
    "       'Latitude_of_Field_Corner_#4 (upper left)',\n",
    "       'Longitude_of_Field_Corner_#4 (upper left)']]\n",
    "\n",
    "df2_filt.isnull().sum() # Treatment is categorical, unlikely to be important\n",
    "                        # City, Farm, Filed - same\n",
    "                        # Soil taxID - too many missing\n",
    "                        # Long & Lat - Only use one - fewer missing in Weather station location \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df2_filt['Treatment'].unique()\n",
    "\n",
    "df2_b = df2.loc[:,['Latitude_of_Field_Corner_#1 (lower left)',\n",
    "       'Longitude_of_Field_Corner_#1 (lower left)','Weather_Station_Latitude (in decimal numbers NOT DMS)',\n",
    "       'Weather_Station_Longitude (in decimal numbers NOT DMS)',]]\n",
    "\n",
    "df2_b\n",
    "df2_b['latitude_diff'] = df2_b['Latitude_of_Field_Corner_#1 (lower left)'] - df2_b['Weather_Station_Latitude (in decimal numbers NOT DMS)']\n",
    "df2_b['longitude_diff'] = df2_b['Longitude_of_Field_Corner_#1 (lower left)'] - df2_b['Weather_Station_Longitude (in decimal numbers NOT DMS)']\n",
    "\n",
    "df2_b.mean()\n",
    "\n",
    "plt.hist(df2_b.loc[~df2_b['latitude_diff'].isnull(),'latitude_diff'])\n",
    "plt.hist(df2_b.loc[~df2_b['longitude_diff'].isnull(),'longitude_diff']) # one has a large difference! (7 decimals - 600 or so km)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_b.loc[df2_b['Latitude_of_Field_Corner_#1 (lower left)'].isna(),['Latitude_of_Field_Corner_#1 (lower left)']] = df2_b[df2_b['Latitude_of_Field_Corner_#1 (lower left)'].isna()]['Weather_Station_Latitude (in decimal numbers NOT DMS)']\n",
    "df2_b.loc[df2_b['Longitude_of_Field_Corner_#1 (lower left)'].isna(),['Longitude_of_Field_Corner_#1 (lower left)']] = df2_b.loc[df2_b['Longitude_of_Field_Corner_#1 (lower left)'].isna()]['Weather_Station_Longitude (in decimal numbers NOT DMS)']\n",
    "df2_b.isna().sum() #only 16 nan remaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filt[df2_filt['Latitude_of_Field_Corner_#1 (lower left)'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filt = df2.loc[:,['Env', 'Year', \n",
    "       'Weather_Station_Latitude (in decimal numbers NOT DMS)',\n",
    "       'Weather_Station_Longitude (in decimal numbers NOT DMS)',\n",
    "       'Latitude_of_Field_Corner_#1 (lower left)',\n",
    "       'Longitude_of_Field_Corner_#1 (lower left)',]]\n",
    "\n",
    "df2_filt.columns = (['Env','Year','WS_Long','WS_Lat','Field_Long','Field_Lat'])\n",
    "\n",
    "df2_filt.loc[df2_filt['Field_Long'].isna(),['Field_Long']] = df2_filt.loc[df2_filt['Field_Long'].isna()]['WS_Long']\n",
    "df2_filt.loc[df2_filt['Field_Lat'].isna(),['Field_Lat']] = df2_filt.loc[df2_filt['Field_Lat'].isna()]['WS_Lat']\n",
    "\n",
    "df2_filt = df2_filt.loc[:,['Env','Year','Field_Long','Field_Lat']]\n",
    "df2_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(df2_filt['Field_Lat'])\n",
    "df2_filt[df2_filt['Field_Lat']>0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load soil data and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/3_Training_Soil_Data_2015_2021.csv\")\n",
    "len(df3) # 141 soil samples\n",
    "df3.isnull().sum() #date received has 17 null\n",
    "#these are missing from almost all \n",
    "#BpH                           130\n",
    "#Zinc ppm Zn                   138\n",
    "#Iron ppm Fe                   138\n",
    "#Manganese ppm Mn              138\n",
    "#Copper ppm Cu                 138\n",
    "#Boron ppm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3['Date Received'].isna()].isnull().sum()  #these have almost no info\n",
    "df3_filt = df3[~df3['Date Received'].isna()]\n",
    "\n",
    "df3_filt.isna().sum()\n",
    "\n",
    "df3_filt.columns # some need dropped \n",
    "#WDRF Buffer pH -- we have 1:1 soil pH for all \n",
    "#comments - w/e\n",
    "#BpH, Zinc, Iron, Manganese, Copper, Boron - missing for almost all\n",
    "#Date received and reported - irrelevant\n",
    "\n",
    "\n",
    "df3_filt = df3_filt.loc[:,['Year', 'Env', 'E Depth',\n",
    "       '1:1 Soil pH', '1:1 S Salts mmho/cm', 'Texture No',\n",
    "       'Organic Matter LOI %', 'Nitrate-N ppm N', 'lbs N/A', 'Potassium ppm K',\n",
    "       'Sulfate-S ppm S', 'Calcium ppm Ca', 'Magnesium ppm Mg',\n",
    "       'Sodium ppm Na', 'CEC/Sum of Cations me/100g', '%H Sat', '%K Sat',\n",
    "       '%Ca Sat', '%Mg Sat', '%Na Sat', 'Mehlich P-III ppm P', '% Sand',\n",
    "       '% Silt', '% Clay', 'Texture']]\n",
    "\n",
    "df3_filt.isna().sum() # few remaining \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filt[df3_filt.isnull().any(axis=1)] #only 6 samples have all the NaN, they're only two locations\n",
    "#df3_filt.to_csv(\"3_soil_pruned.csv\") #manually interpolated in excel\n",
    "\n",
    "df3_filt = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/3_Soil_ManInterp_noNA.csv\")\n",
    "df3_filt.isna().sum() # All NAs are gone\n",
    "\n",
    "#df3_filt.loc[:,'Texture'] = pd.Categorical(df3_filt.loc[:,'Texture']).codes #replace texture with category\n",
    "#df3_filt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and prune preprocessed weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/4_weather_summarized_by_week_noNAs.csv\")\n",
    "df4.isna().sum() # No NAs\n",
    "df4_filt = df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/5_Geno_LD_filt_noNAs_01062023.csv\")\n",
    " # No NAs - great "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read EC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(\"/home/sbusato/G2F/Data/Data_for_merge/Original/6_Training_EC_Data_2014_2021.csv\")\n",
    "df6.isna().sum().sum() # No NAs - great \n",
    "df6_filt = df6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.merge(df1_filt,df2_filt, on=[\"Env\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123 = pd.merge(df12,df3_filt, on=[\"Env\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1234 = pd.merge(df123,df4_filt, on=[\"Env\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1234 = df1234.rename(columns = {'Hybrid_orig_name':'Hybrid'})\n",
    "df5 = df5.rename(columns = {'Unnamed: 0':'Hybrid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12345 = pd.merge(df1234,df5, on=['Hybrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123456 = pd.merge(df12345,df6_filt, on=[\"Env\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123456.to_csv(\"all_df_merge_01062023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df123456.isna().sum() \n",
    "a[a>0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
